{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMAkgcEQmmNj"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: Ayesha Parveen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Fie2RwmmNp"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUzv1MGmmNq"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EilN1rhkmmNq"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrEC3ztzmmNr",
        "outputId": "e28d7a9d-811a-48cb-a156-62dd3323c219"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNeYJIYKmmNr"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a506N9sYmmNr",
        "outputId": "5b51725e-d9d9-4087-9541-de5ffc9332c8"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    # <fill the function>\n",
        "    # ...\n",
        "    results = numpy.zeros((len(y),num_class))\n",
        "    for i, label in enumerate(y):\n",
        "      results[i, label] = 1\n",
        "    return results\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbytBjp_mmNs"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19-2EAvummNs"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT3N-GNnmmNs",
        "outputId": "f81e7f0f-af64-4e86-9281-3f1adb479e7b"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihsHFBSCmmNt"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er7lSNDjmmNt"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZLOGN3_mmNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e27c6f5-dab5-48e4-961d-5241e0ec55ce"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32,(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 556,586\n",
            "Trainable params: 555,690\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-lW1saAmmNu"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-4  \n",
        "# to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4-VrCGHmmNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a48c66-aff7-4416-b2ed-7346ceb3f791"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=32, epochs=30, validation_data=(x_val, y_val))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1250/1250 [==============================] - 13s 7ms/step - loss: 2.0902 - acc: 0.2886 - val_loss: 1.4362 - val_acc: 0.4845\n",
            "Epoch 2/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 1.4354 - acc: 0.4876 - val_loss: 1.2838 - val_acc: 0.5494\n",
            "Epoch 3/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2392 - acc: 0.5584 - val_loss: 1.0971 - val_acc: 0.6111\n",
            "Epoch 4/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1186 - acc: 0.6027 - val_loss: 1.0581 - val_acc: 0.6234\n",
            "Epoch 5/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0367 - acc: 0.6356 - val_loss: 0.9471 - val_acc: 0.6651\n",
            "Epoch 6/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9572 - acc: 0.6618 - val_loss: 0.9545 - val_acc: 0.6635\n",
            "Epoch 7/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8947 - acc: 0.6837 - val_loss: 0.8756 - val_acc: 0.6905\n",
            "Epoch 8/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8483 - acc: 0.6988 - val_loss: 0.8722 - val_acc: 0.6968\n",
            "Epoch 9/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8053 - acc: 0.7158 - val_loss: 0.7878 - val_acc: 0.7228\n",
            "Epoch 10/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7520 - acc: 0.7329 - val_loss: 0.7587 - val_acc: 0.7343\n",
            "Epoch 11/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7226 - acc: 0.7441 - val_loss: 0.7338 - val_acc: 0.7451\n",
            "Epoch 12/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6893 - acc: 0.7547 - val_loss: 0.7327 - val_acc: 0.7433\n",
            "Epoch 13/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6648 - acc: 0.7680 - val_loss: 0.7308 - val_acc: 0.7436\n",
            "Epoch 14/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6361 - acc: 0.7764 - val_loss: 0.6681 - val_acc: 0.7661\n",
            "Epoch 15/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6163 - acc: 0.7818 - val_loss: 0.6846 - val_acc: 0.7665\n",
            "Epoch 16/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5828 - acc: 0.7965 - val_loss: 0.6674 - val_acc: 0.7701\n",
            "Epoch 17/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5561 - acc: 0.8063 - val_loss: 0.6805 - val_acc: 0.7673\n",
            "Epoch 18/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5461 - acc: 0.8073 - val_loss: 0.6365 - val_acc: 0.7796\n",
            "Epoch 19/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5166 - acc: 0.8171 - val_loss: 0.6309 - val_acc: 0.7824\n",
            "Epoch 20/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5057 - acc: 0.8197 - val_loss: 0.6178 - val_acc: 0.7901\n",
            "Epoch 21/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4820 - acc: 0.8282 - val_loss: 0.6261 - val_acc: 0.7883\n",
            "Epoch 22/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4696 - acc: 0.8337 - val_loss: 0.6204 - val_acc: 0.7917\n",
            "Epoch 23/30\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4634 - acc: 0.8344 - val_loss: 0.6242 - val_acc: 0.7887\n",
            "Epoch 24/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4327 - acc: 0.8440 - val_loss: 0.6382 - val_acc: 0.7938\n",
            "Epoch 25/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4310 - acc: 0.8467 - val_loss: 0.6141 - val_acc: 0.7977\n",
            "Epoch 26/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4123 - acc: 0.8535 - val_loss: 0.6007 - val_acc: 0.8010\n",
            "Epoch 27/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4093 - acc: 0.8551 - val_loss: 0.5944 - val_acc: 0.8062\n",
            "Epoch 28/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3881 - acc: 0.8629 - val_loss: 0.6050 - val_acc: 0.8025\n",
            "Epoch 29/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3801 - acc: 0.8626 - val_loss: 0.6107 - val_acc: 0.8060\n",
            "Epoch 30/30\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3644 - acc: 0.8688 - val_loss: 0.6004 - val_acc: 0.8101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZIa25SmmNv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "90a42fc0-152c-44b1-aa2e-7242d516e811"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjFyiSiemmNv"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aZfiOSVmmNw"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBHaZEPammNw"
      },
      "source": [
        "# <Compile your model again (using the same hyper-parameters)>\n",
        "# ...\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-5  \n",
        "# to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7opVD0CmmNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d59b1cb-ccac-4b7c-84f4-ebc7a63a9959"
      },
      "source": [
        "# <Train your model on the entire training set (50K samples)>\n",
        "# <Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "# <Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "# ...\n",
        "history = model.fit(x_train, y_train_vec, batch_size=32, epochs=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 0.4079 - acc: 0.8626\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3932 - acc: 0.8650\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3870 - acc: 0.8703\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3791 - acc: 0.8701\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3749 - acc: 0.8691\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3712 - acc: 0.8710\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3701 - acc: 0.8731\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3621 - acc: 0.8731\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3655 - acc: 0.8756\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3571 - acc: 0.8763\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3522 - acc: 0.8798\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3609 - acc: 0.8771\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3535 - acc: 0.8780\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3505 - acc: 0.8779\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3475 - acc: 0.8798\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3490 - acc: 0.8790\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3449 - acc: 0.8809\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3393 - acc: 0.8834\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3437 - acc: 0.8824\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3352 - acc: 0.8835\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3474 - acc: 0.8817\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3337 - acc: 0.8825\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3265 - acc: 0.8862\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3237 - acc: 0.8870\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3266 - acc: 0.8860\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3140 - acc: 0.8914\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3305 - acc: 0.8867\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3229 - acc: 0.8868\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3232 - acc: 0.8870\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3221 - acc: 0.8892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tHYfUUEmmNw"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf8IUu7lmmNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bad733a-d3d4-4385-e903-564de1d973b8"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5424 - acc: 0.8263\n",
            "loss = 0.5423923134803772\n",
            "accuracy = 0.8263000249862671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cduAlzwDmmNx"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}